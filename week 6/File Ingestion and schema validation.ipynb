{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bdf921",
   "metadata": {},
   "source": [
    "# LISUM09, Week 6, File ingestion and schema validation\n",
    "## Name: Laâroussi Saâdeddine\n",
    "## Mail : laar.saad.eddine@gmail.com\n",
    "## Country : Morocco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f184db",
   "metadata": {},
   "source": [
    "Tasks for this week's assignement are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4d9a8",
   "metadata": {},
   "source": [
    "## 1) Choosing data of 2+ GB. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39643e86",
   "metadata": {},
   "source": [
    "Data was taken from kaggle.\n",
    "\n",
    "Data is about 'StackSample: 10% of Stack Overflow Q&A'\n",
    "\n",
    "Link to data : https://www.kaggle.com/datasets/stackoverflow/stacksample\n",
    "\n",
    "Size of data as of 06/06/2022 : 3.6 GB (Questions.csv : 1.87 GB, Anserws.csv: 1.57 GB, Tags : 0.63 GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e16991",
   "metadata": {},
   "source": [
    "## 2) Reading data using different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66eb0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "308c395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  320.41127972799995\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "df_pd = pd.read_csv('Dataset/Questions.csv',encoding='ISO-8859-1')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "253dc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "405c9ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  2.274378377000062\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "df_dd = dd.read_csv('Dataset/Questions.csv',encoding='ISO-8859-1')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb576478",
   "metadata": {},
   "source": [
    "Dask is faster than pandas\n",
    "\n",
    "I tried using modin but my PC crashes\n",
    "\n",
    "ray isn't available for python version after 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd16a34",
   "metadata": {},
   "source": [
    "## 3) Performing basic validation on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d94bd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'OwnerUserId', 'CreationDate', 'ClosedDate', 'Score', 'Title',\n",
       "       'Body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edce0172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testutility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5953c7",
   "metadata": {},
   "source": [
    "Renaming columns to test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac014b03",
   "metadata": {},
   "source": [
    "## 4) Creating YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1d5b749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: Questions\n",
    "file_name: Questions\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - id\n",
    "    - owneruserid\n",
    "    - creationdate\n",
    "    - closeddate\n",
    "    - score\n",
    "    - title\n",
    "    - body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5f54c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import testutility as util\n",
    "config_data = util.read_config_file(\"file.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55e9be9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'Questions',\n",
       " 'file_name': 'Questions',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['id',\n",
       "  'owneruserid',\n",
       "  'creationdate',\n",
       "  'closeddate',\n",
       "  'score',\n",
       "  'title',\n",
       "  'body']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd2ef2",
   "metadata": {},
   "source": [
    "## 5) Validation and ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e5cc5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3369: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2008-08-01T13:57:07Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>SQLStatement.execute() - multiple queries in o...</td>\n",
       "      <td>&lt;p&gt;I've written a database generation script i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2008-08-01T14:41:24Z</td>\n",
       "      <td>2012-12-26T03:45:49Z</td>\n",
       "      <td>144</td>\n",
       "      <td>Good branching and merging tutorials for Torto...</td>\n",
       "      <td>&lt;p&gt;Are there any really good tutorials explain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2008-08-01T15:50:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>&lt;p&gt;Has anyone got experience creating &lt;strong&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>2089740.0</td>\n",
       "      <td>2008-08-01T18:42:19Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Function for creating color wheels</td>\n",
       "      <td>&lt;p&gt;This is something I've pseudo-solved many t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2008-08-01T23:22:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>&lt;p&gt;I have a little game written in C#. It uses...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  OwnerUserId          CreationDate            ClosedDate  Score  \\\n",
       "0   80         26.0  2008-08-01T13:57:07Z                   NaN     26   \n",
       "1   90         58.0  2008-08-01T14:41:24Z  2012-12-26T03:45:49Z    144   \n",
       "2  120         83.0  2008-08-01T15:50:08Z                   NaN     21   \n",
       "3  180    2089740.0  2008-08-01T18:42:19Z                   NaN     53   \n",
       "4  260         91.0  2008-08-01T23:22:08Z                   NaN     49   \n",
       "\n",
       "                                               Title  \\\n",
       "0  SQLStatement.execute() - multiple queries in o...   \n",
       "1  Good branching and merging tutorials for Torto...   \n",
       "2                                  ASP.NET Site Maps   \n",
       "3                 Function for creating color wheels   \n",
       "4  Adding scripting functionality to .NET applica...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>I've written a database generation script i...  \n",
       "1  <p>Are there any really good tutorials explain...  \n",
       "2  <p>Has anyone got experience creating <strong>...  \n",
       "3  <p>This is something I've pseudo-solved many t...  \n",
       "4  <p>I have a little game written in C#. It uses...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_type = config_data['file_type']\n",
    "source_file = \"DataSet/\" + config_data['file_name'] + f'.{file_type}'\n",
    "df = pd.read_csv(source_file,config_data['inbound_delimiter'],encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0603c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.col_header_val(df_pd,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47805620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Id','OwnerUserId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a78bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'Id':'_  ID__','OwnerUserId': 'owner USER__ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92d2f61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation failed\n",
      "Following File columns are not in the YAML file ['owner_user_id']\n",
      "Following YAML columns are not in the file uploaded ['closeddate', 'owneruserid', 'score', 'body', 'title', 'creationdate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.col_header_val(df,config_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4126e26",
   "metadata": {},
   "source": [
    "## 6) Writing file with | pipeline in gz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1171cca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = \"DataSet/\" + config_data['file_name']+ \" out\" + f'.{file_type}.gz'\n",
    "\n",
    "df_pd.to_csv(filename, sep=config_data['outbound_delimiter'], compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12d18531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "origin_size = os.path.getsize(source_file)\n",
    "compressed_size = os.path.getsize(filename)\n",
    "number_rows = df_pd.shape[0]\n",
    "number_columns= df_pd.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d151290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 1923682009Ko\n",
      "Compressed size: 616475376Ko\n",
      "Number of rows: 1264216\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Original size: \" + f'{origin_size}' +\"Ko\")\n",
    "print(\"Compressed size: \" + f'{compressed_size}' +\"Ko\")\n",
    "print(\"Number of rows: \" + f'{number_rows}')\n",
    "print(\"Number of columns: \"+  f'{number_columns}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
